{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a6430f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc6bc6e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define the sigmoid activation function\n",
    "def sigmoid(y):\n",
    "    return 1 / (1 + np.exp(-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cde370a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define the prediction function\n",
    "def predict(x, w, b):\n",
    "    y_pred = x @ w + b\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dff113",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define the cost computation function for logistic regression\n",
    "def compute_cost(x, y, y_pred):\n",
    "    cost = y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)\n",
    "    cost = np.sum(cost, axis=0)\n",
    "    return -cost / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751978f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define the gradient computation function for logistic regression\n",
    "def gradient(x, y, y_pred):\n",
    "    err = y_pred - y\n",
    "    dw = x.T @ err\n",
    "    db = np.sum(err, axis=0)\n",
    "    return dw / m, db / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a967a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define the gradient descent optimization function\n",
    "def gradient_descent(x, y, w, b, lr, itera):\n",
    "    for k in range(itera + 1):\n",
    "        y_pred = x @ w + b\n",
    "        y_pred = sigmoid(y_pred)\n",
    "        dw, db = gradient(x, y, y_pred)\n",
    "        w = w - lr * dw\n",
    "        b = b - lr * db\n",
    "        if k % 50 == 0:\n",
    "            cost = compute_cost(x, y, y_pred)\n",
    "            print(f\"After {k} iteration : {cost}\\n\")\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"D:\\\\HP\\\\users\\\\OneDrive\\\\Desktop\\\\AI ML\\\\train and test\\\\classification_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ce5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input features and labels\n",
    "x = data.iloc[:29000, 2:].values / 255\n",
    "y = data.iloc[:29000, 1:2].values\n",
    "m, n = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c81b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape each row to a 28x28 image (assuming they are 28x28 images)\n",
    "img_size = 28\n",
    "x_images = x.reshape(-1, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a random subset of images\n",
    "indices = np.random.choice(m, size=20, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "gs = gridspec.GridSpec(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, index in enumerate(indices):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    ax.imshow(x_images[index], cmap='gray')\n",
    "    ax.set_title(f\"Class {int(y[index])}\")\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cadce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare one-hot encoded labels for logistic regression\n",
    "y2 = np.zeros((m, 10))\n",
    "for i in range(m):\n",
    "    y2[i, int(y[i])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "w = np.zeros((n, 10))\n",
    "b = np.zeros((1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 1e-4\n",
    "itera = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f05f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "w, b = gradient_descent(x, y2, w, b, lr, itera)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
